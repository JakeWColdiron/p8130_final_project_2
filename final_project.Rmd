---
title: "Final Project"
output: github_document
---

```{r}
library(gtsummary)
library(tidyverse)
library(car)
library(caret)
library(corrplot)
library(glmnet)
library(leaps)
library(pROC)


set.seed(123)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))

```

```{r}
data = read_csv("./data/data.csv") |>
  janitor::clean_names()

summary(data)
data=data|>select(-survival_months)
str(data)
```

```{r}
# Check for missing data
colSums(is.na(data))
```

```{r}
# Convert character to factor for regression analysis
clean_data = data |>
  mutate(
    race = as.numeric(factor(race, levels = c("White", "Black", "Other"))) - 1,
    marital_status = as.numeric(factor(marital_status, levels = c("Married", "Single", "Divorced", "Widowed", "Separated"))) - 1,
    t_stage = as.numeric(factor(t_stage, levels = c("T1", "T2", "T3", "T4"))) - 1,
    n_stage = as.numeric(factor(n_stage, levels = c("N1", "N2", "N3"))) - 1,
    x6th_stage = as.numeric(factor(x6th_stage, levels = c("IIA", "IIB", "IIIA", "IIIB", "IIIC"))) - 1,
    differentiate = as.numeric(factor(differentiate, levels = c("Undifferentiated", "Poorly differentiated", "Moderately differentiated", "Well differentiated"))) - 1,
    grade = as.numeric(factor(grade, levels = c("1", "2", "3", "anaplastic; Grade IV"))),
    a_stage = as.numeric(factor(a_stage, levels = c("Regional", "Distant"))) - 1,
    estrogen_status = as.numeric(factor(estrogen_status, levels = c("Negative", "Positive"))) - 1,
    progesterone_status = as.numeric(factor(progesterone_status, levels = c("Negative", "Positive"))) - 1,
    status = as.numeric(factor(status, levels = c("Dead", "Alive"))) - 1)|>
  rename(regional_node_positive = reginol_node_positive)

summary(clean_data)
str(clean_data)

colSums(is.na(clean_data))
```



#Model fitting
#Based on boxplots, transformaiton is necesessary to reduce outliers 
#cube root of tumor size
#log of regional_node_examied
#log of regional_node_positive
#Figure 1 
```{r}
proj2 = data |>
tbl_summary(by="status",
  missing_text = "(Missing)", # counts missing values
  statistic = list(all_continuous() ~ "mean={mean} (min={min}, max={max}, sd={sd})",
                   all_categorical() ~ "n={n} (p={p}%)") # stats for categorical
 # specify variables to include
  ) |>
bold_labels()  |>
italicize_levels()


clean_data2=clean_data
clean_data2$tumor_size= (clean_data$tumor_size)^(1/3)
clean_data2$regional_node_examined = log(clean_data$regional_node_examined)
clean_data2$regional_node_positive = log(clean_data$regional_node_positive)

```

#Find correlation
```{R}
corplot=cor(clean_data2)
corrplot(corplot)
#tumor_size vs t_stage = 0.801
#grade=differentiate =>1
#n_stage = x6th_stage => 0.881
#n_stage = regional positive status =>0.838073333
selected_data = clean_data2 |>
  select(-tumor_size, -grade,-n_stage,-regional_node_positive,-x6th_stage)

corplot=cor(selected_data)
corrplot(corplot)
```
#MAybe useful
```{R}

model = glm(status ~ (factor(marital_status)*factor(race)*age +factor(t_stage) + factor(differentiate) + factor(a_stage) + factor(estrogen_status)+factor(progesterone_status) +regional_node_examined),
             family = binomial(link = "logit"), data = selected_data)
```

#Separate training and testing set (80% training 20% testing )
```{R}
# Calculate the size of each of the data sets
data_size <- nrow(clean_data2)
train_size <- floor(0.8 * data_size)

# Create a random sample of row indices for the training set
train_indices <- sample(seq_len(data_size), size = train_size)

# Subset the data into training and testing sets
train_set <- clean_data2[train_indices, ]
test_set <- clean_data2[-train_indices, ]

```


#Forward, BackWard
```{R}

selected_train = train_set |>
  select(-tumor_size, -grade,-n_stage,-regional_node_positive,-x6th_stage)

null_model = glm(status ~ 1, family = binomial(link = "logit"), data = selected_train)

full_model=glm(status ~ . , family = binomial(link = "logit"), data = selected_train)



step_modelF = step(null_model, scope = list(lower = null_model, upper = full_model), 
                   direction = "forward")

step_model = step(full_model, direction = "backward")
summary(step_model)
summary(step_modelF)
anova(step_model,step_modelF,test="Chisq")
#same 

test_predictions_log_oddsStep <- predict(step_model, newx = as.matrix(test_set))
test_predictions_probStep <- plogis(test_predictions_log_oddsStep)

```


#Elastic Net
```{R}


# Prepare your data
# Let's say 'data' is your dataframe and 'target' is the name of your response variable
X <- as.matrix(train_set[, setdiff(names(train_set), "status")])  # Predictor variables
y <- train_set$status  # Response variable

lambda_seq <- 10^seq(-3, 0, by = .01)

# Fit the LASSO logistic regression model
lasso_model <- glmnet(X, y, family = "binomial", alpha = 0.5, lambda = lambda_seq)
# Use cross-validation to find the optimal lambda
cv_model <- cv.glmnet(X, y, family = "binomial", alpha = 0.5, type.measure = "class")
plot(cv_model$lambda)
# Best lambda value
best_lambda <- cv_model$lambda.min
# Refit the model using the best lambda
final_model <- glmnet(X, y, family = "binomial", alpha = 0.5, lambda = best_lambda)

test_set2 <- test_set|> select(-status)

#test_predictions_log_odds <- predict(final_model, newx = as.matrix(test_set2), s = best_lambda)

test_predictions_log_odds <- predict(final_model, newx = as.matrix(test_set2))

# Convert log-odds to probabilities
test_predictions_probElastic <- plogis(test_predictions_log_odds)
# Create the ROC curve
roc_curve <- roc(response = as.matrix(test_set$status), predictor = as.numeric(test_predictions_probElastic) )

auc(roc_curve)

#Now step model


roc_curveStep <- roc(response = (test_set$status), predictor = as.numeric(test_predictions_probStep))

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "#1c61b6", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "red") # Add a reference line
```


